name: Web Scraping

on:
  schedule:
    - cron: '0 0 * * *'  # Schedule it to run once a day at midnight
  workflow_dispatch:  # Trigger manually via the GitHub UI

jobs:
  webscraping:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v2
      
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'  # You can use a different Python version if needed

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb
        sudo apt --fix-broken install -y
        sudo apt-get install -y libx11-xcb1 libxcomposite1 libxrandr2 libglu1-mesa libxi6 libgconf-2-4
        CHROME_VERSION=$(google-chrome --version | sed 's/[^0-9.]//g' | cut -d. -f1) && \
        wget -O /tmp/chromedriver.zip "https://chromedriver.storage.googleapis.com/$(curl -s https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_VERSION})/chromedriver_linux64.zip" && \
        unzip /tmp/chromedriver.zip chromedriver -d /usr/bin/ && \
        chmod +x /usr/bin/chromedriver
        pip install -r requirements.txt  # Install Python dependencies

    - name: Run web scraping script
      run: |
        python3 test.py  # Replace with your script name
